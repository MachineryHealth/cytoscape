
\chapter{EMアルゴリズム}

\section{EMアルゴリズムの概要}
\label{EM_algo_overview}

EMアルゴリズムは最尤推定量を数値的に求めるアルゴリズムです。
今、パラメータ\(\theta\)によってきまる確率関数を\(P(x|\theta)\)とします。
観測値\(x\)が与えられたとき、母数\(\theta\)をどのように推定すればいいでしょうか？

最尤推定法では観測値\(x\)を定数として、\(P(x|\theta)\)が最大になる
ような\(\theta\)を真の\(\theta\)の推定量とします。この推
定量すなわち、

\begin{equation}
\theta_{\rm max}=\mbox{argmax}_{\theta}P(x|\theta)
=\mbox{argmax}_{\theta}\log P(x|\theta)
\end{equation}

\noindent
を最尤推定量といいます。最尤推定量は一致性や漸近正規性など統計解析を
する上で有用な性質を持っています\cite{statistics1,statistics2}。
全ての確率変数が観測可能なケースでは多くの場合、
最尤推定量は解析的に求めることが可能です。しかし、確率変数の一部が観測
不能な場合、最尤推定量を解析的に求めるのは多くの場合、困難です。そこで
EMアルゴリズムではこれを数値的に求めます。

なお\(\theta\)を関数への入力と考え、\(P(x|\theta)\)を\(\theta\)が真の
\(\theta\)の推定量としての尤もらしさを表す関数と考えるとき、
\(P(x|\theta)\)を尤度関数、その値自体を尤度といいます。

観測可能な確率変数を\(x\)、観測不能な確率変数を\(y\)とすると、

\begin{equation}
\mbox{argmax}_{\theta}\log P(x|\theta)=
\mbox{argmax}_{\theta}\left(\log \sum_{y}P(x,y|\theta)  \right)
\end{equation}

\noindent
となります。
また\(P(x,y|\theta)=P(y|x,\theta)P(x|\theta)\)を移項して両辺の対数をとると、

\begin{equation}
\log P(x|\theta) = \log P(x,y|\theta) - \log P(y|x,\theta)
\label{eq_EM5}
\end{equation}

\noindent
となります。
\(\theta \)のとりあえずの推定量を\(\theta^{t}\)として、式\ref{eq_EM5}の
両辺に\(P(y|x,\theta^{t}\))を掛けて、\(y\)について和をとると、

\[
\mbox{左辺} = \sum_{y}P(y|x,\theta^{t})\log P(x|\theta) = \log P(x|\theta)
\]
\[
\mbox{右辺} = \sum_{y}P(y|x,\theta^{t})\log P(x,y|\theta)
 - \sum_{y}P(y|x,\theta^{t}) \log P(y|x,\theta)
\]

従って、

\begin{equation}
\log P(x|\theta) = \sum_{y}P(y|x,\theta^{t}) \log P(x,y|\theta)
- \sum_{y}P(y|x,\theta^{t})\log P(y|x,\theta)
\label{EM_eq_ptheta1}
\end{equation}

\noindent
となります。ここで、

\begin{equation}
Q(\theta|\theta^{t})
=\sum_{y}P(y|x,\theta^{t})\log P(x,y|\theta)
\label{EM_QQ}
\end{equation}

\noindent
とおいて、式\ref{EM_eq_ptheta1}の両辺から\(\log P(x|\theta^{t})\)を引くと、

\begin{equation}
\log P(x|\theta)-\log P(x|\theta^{t}) = Q(\theta|\theta^{t}) - Q(\theta^{t}|\theta^{t}) +
\sum_{y}P(y|x,\theta^{t})\log \frac{P(y|x,\theta^{t})}{P(y|x,\theta)}
\label{EM_eq_ptheta2}
\end{equation}

\noindent
となります。式\ref{EM_eq_ptheta2}の右辺の
\(\sum_{y}P(y|x,\theta^{t})\log \frac{P(y|x,\theta^{t})}{P(y|x,\theta)}\)
は増加情報量であり、\(\sum_{y}P(y|x,\theta^{t})\log 
\frac{P(y|x,\theta^{t})}{P(y|x,\theta)}\geq 0\)となるので(節
\ref{rel_entropy}参照)、

\begin{equation}
\log P(x|\theta) - \log P(x|\theta^{t})
\geq Q(\theta|\theta^{t}) - Q(\theta^{t}|\theta^{t})
\label{EM_eq_ptheta3}
\end{equation}

が成立します。
ここで式\ref{EM_eq_ptheta3}の\(\theta\)に\(\theta^{t+1}\)を代入すると、
\(Q(\theta^{t+1}|\theta^{t}) \geq Q(\theta^{t}|\theta^{t})\)が成立すれば、

\begin{equation}
\log P(x|\theta^{t+1}) - \log P(x|\theta^{t})
 \geq Q(\theta^{t+1}|\theta^{t}) - Q(\theta^{t}|\theta^{t}) \geq 0
\end{equation}

\noindent
となります。\(\theta^{t+1}=\mbox{argmax}_{\theta} Q(\theta|\theta^{t})\)とおけば、
 \(Q(\theta^{t+1}|\theta^{t}) \geq Q(\theta^{t}|\theta^{t})\)が成立するので、
 \(\theta^{t}\)を\(\theta^{t+1}\)と置き換えることによって\(\log P(x|\theta^{t})\)が
 \(Q(\theta^{t+1}|\theta^{t}) - Q(\theta^{t}|\theta^{t})\)以上上昇することになります。

また、\(\theta^{t+2}=\mbox{argmax}_{\theta} Q(\theta|\theta^{t+1})\)とおけば、
\(Q(\theta^{t+2}|\theta^{t+1}) \geq Q(\theta^{t+1}|\theta^{t+1})\)となり、
 \(\log P(x|\theta^{t+2}) - \log P(x|\theta^{t+1})
 \geq Q(\theta^{t+2}|\theta^{t+1}) - Q(\theta^{t+1}|\theta^{t+1}) \geq 0\)が成立します。
よって、
 \(\theta^{t+1}\)を\(\theta^{t+2}\)と置き換えることによって\(\log P(x|\theta^{t+1})\)が
 \(Q(\theta^{t+2}|\theta^{t+1}) - Q(\theta^{t+1}|\theta^{t+1})\)以上上昇
することになります。

これを繰り返して、\(\theta^{t}\)から\(\theta^{t+1}\)、\(\theta^{t+1}\)か
ら\(\theta^{t+2}\)、\(\cdots \)を求めていくと、
\(P(x|\theta^{t+})\)はどんどん上昇していきます。このようにして数値的に
\(P(x|\theta^{t+})\)を増していくのがEMアルゴリズムであり、以下のように
まとめることができます。

\begin{description}
\item[E-Step] \(Q(\theta|\theta^{t})=\sum_{y}P(y|x,\theta^{t})\log P(x,y|\theta)
 =E_{y}[\log P(x,y|\theta)|x,\theta^{t}]\)の計算。観測値\(x\)と現在の推定量\(\theta^{t}\)を用いて、
観測不能データ\(y\)に関する\(\log P(x,y|\theta)\)の平均値を求める
\item[M-Step] \(Q(\theta|\theta^{t})\)の\(\theta\)に関する最大化。
\(\theta^{t+1}=\mbox{argmax}_{\theta}Q(\theta|\theta^{t})\)を求め、これを新たな推定量とする。
\end{description}



\section{K平均アルゴリズムの導出}

では、EMアルゴリズムを用いてK平均アルゴリズムを導出してみましょう。
確率変数\(x_{i}(1\leq x \leq m)\)が平均\(\mu_{1},\mu_{2},\cdots\)または\(\mu_{k}\)の
いずれかの正規分布に従うとします。但し分散はいずれも\(\sigma^{2}\)とします。

また変数\(y_{ij}\)を

\begin{displaymath}
y_{ij}=\left\{
\begin{array}{ll}
1 & {\rm if}\ x_{i} \sim N(\mu_{j}, \sigma^{2})\\
0 & {\rm otherwise}
\end{array}
\right.
\end{displaymath}

\noindent
と定義します。クラスタリング対象となる要素\(i\)の確率変数は
\((x_{i},y_{i1},y_{i2},\cdots,y_{ik})\)で表されることになりますが、\(x_{i}\)が
観測可能な確率変数、\(y_{i1},\cdots,y_{ik}\)が観測不能な確率変数となります。
\(i\)が\(k\)個の正規分布のうち、どこに従う確率も\(\frac{1}{k}\)とすると、
\((x_{i},y_{i1},y_{i2},\cdots,y_{ik})\)の分布を表す確率関数は式\ref{gaussian}を
もとにして、

\begin{equation}
P(x_{i},y_{i1},y_{i2},\cdots,y_{ik}|\mu)
=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2\sigma^{2}}\sum_{j=1}^{k}y_{ij}(x_{i}-\mu_{i})^{2}}
\label{EM_kmeans1}
\end{equation}

\noindent
となります。但し、\(\mu\)は\(\mu_{1},\cdots,\mu_{k}\)を表します。式
\ref{EM_kmeans1}を\(m\)個の要素についての積に書き直し、さらに両辺につい
て自然対数をとると、

\begin{displaymath}
\log_{e} P(x,y|\mu)= \log_{e} \prod_{i=1}^{m}P(x_{i},y_{i1},y_{i2},\cdots,y_{ik}|\mu)
\end{displaymath}

\begin{displaymath}
=\sum_{i=1}^{m}\log_{e} P(x_{i},y_{i1},y_{i2},\cdots,y_{ik}|\mu)
\end{displaymath}
\begin{equation}
=\sum_{i=1}^{m}\left(\log_{e}\frac{1}{\sqrt{2\pi}\sigma} - \frac{1}{2\sigma^{2}}\sum_{j=1}^{k}y_{ij}(x_{i}-\mu_{j})^{2}\right)
\end{equation}

\noindent
と表すことができます。

従ってE-Stepでは、

\begin{displaymath}
Q(\mu|\mu^{t})=\sum_{y}P(y|x,\mu^{t})\log_{e} P(x,y|\mu)
\end{displaymath}
\begin{displaymath}
=E_{y}[\log_{e} P(x,y|\mu)|x,\mu^{t}]
=E_{y}\left[\sum_{i=1}^{m}\left(\log_{e}\frac{1}{\sqrt{2\pi}\sigma}
- \frac{1}{2\sigma^{2}}\sum_{j=1}^{k}y_{ij}(x_{i} - \mu_{j})^{2}\right)|x,\mu^{t}\right]
\end{displaymath}
\begin{displaymath}
=\sum_{i=1}^{m}\left(\log_{e}\frac{1}{\sqrt{2\pi}\sigma}
- \frac{1}{2\sigma^{2}}\sum_{j=1}^{k}E[y_{ij}|x,\mu^{t}](x_{i} - \mu_{j})^{2}\right)
\end{displaymath}

\noindent
を計算します。さらに\(E\)の部分は、

\begin{displaymath}
E[y_{ij}|x,\mu^{t}]= \sum_{y_{ij}=0,1}P(y_{ij}|x_{i},\mu^{t})y_{ij}=P(y_{ij}=1|x_{i},\mu^{t})
\end{displaymath}
\begin{displaymath}
=\frac{\frac{1}{\sqrt{2\pi}\sigma}e^{-{\frac{1}{2\sigma^{2}}(x_{i}-\mu_{j}^{t})^{2}}}}
      {\sum_{v=1}^{k}
       \frac{1}{\sqrt{2\pi}\sigma}e^{-{\frac{1}{2\sigma^{2}}(x_{i}-\mu_{v}^{t})^{2}}}}
=\frac{e^{-{\frac{1}{2\sigma^{2}}(x_{i}-\mu_{j}^{t})^{2}}}}
      {\sum_{v=1}^{k}
       e^{-{\frac{1}{2\sigma^{2}}(x_{i}-\mu_{v}^{t})^{2}}}}
\end{displaymath}

\noindent
となります。

M-Stepでは、

\begin{displaymath}
\mu^{t+1}=\mbox{argmax}_{\mu}Q(\mu|\mu^{t})
\end{displaymath}
\begin{displaymath}
=\mbox{argmax}_{\mu}\sum_{i=1}^{m}\left(\log_{e}\frac{1}{\sqrt{2\pi}\sigma}
- \frac{1}{2\sigma^{2}}\sum_{j=1}^{k}E[y_{ij}|x,\mu^{t}](x_{i} - \mu_{j})^{2}\right)
\end{displaymath}
\begin{equation}
=\mbox{argmin}_{\mu}\sum_{i=1}^{m}\sum_{j=1}^{k}E[y_{ij}|x,\mu^{t}](x_{i} - \mu_{j})^{2}
\label{kmeans_M_step}
\end{equation}

\noindent
を求めます。そのためには式\ref{kmeans_M_step}を各クラスター\(v\)の平均
\(\mu_{v}\)で偏微分して、

\begin{displaymath}
\frac{\partial}{\partial \mu_{v}}
\sum_{i=1}^{m}\sum_{j=1}^{k}E[y_{ij}|x,\mu^{t}](x_{i}-\mu_{j})^{2}
=\frac{\partial}{\partial \mu_{v}}
\sum_{i=1}^{m}E[y_{iv}|x,\mu^{t}](x_{i}-\mu_{v})^{2}
\end{displaymath}
\begin{displaymath}
=-2\sum_{i=1}^{m}E[y_{iv}|x,\mu^{t}](x_{i}-\mu_{v})=0
\end{displaymath}

\noindent
とおけば、\(\mu_{v}=\frac{\sum_{i=1}^{m}E[y_{iv}|x,\mu^{t}]x_{i}}{\sum_{i=1}^{m}E[y_{iv}|x,\mu^{t}]}\)となるので、

\begin{displaymath}
\mu_{v}^{t+1}=\frac{\sum_{i=1}^{m}E[y_{iv}|x,\mu^{t}]x_{i}}{\sum_{i=1}^{m}E[y_{iv}|x,\mu^{t}]}
\end{displaymath}

\noindent
がM-Stepとなります。

節\ref{section_kmeans}では\(E[y_{iv}|x,\mu^{t}]\)の代わりに、\(N_{b}[y_{iv}|x,\mu^{t}]\)を使っており、
その定義は以下の通りです。

\begin{displaymath}
N_{b}[y_{ij}|x,\mu^{t}]=\left\{
\begin{array}{ll}
1 & {\rm if}\ j=\mbox{argmin}_{j'}(x_{i}-\mu_{j'}^{t})^{2}\\
0 & {\rm otherwise}
\end{array}\right.
\end{displaymath}



\section{隠れマルコフモデルのパラメータ推定}
\label{EM_HMM}

\begin{figure}
\begin{center}
\includegraphics[scale=0.8]{Figures_EPS/hmm_count.eps}
\end{center}
\caption{隠れマルコフモデル上の通過経路および出力記号の例}
\label{hmm_count}
\begin{quotation}
"TACGATG"が出力されたときに通った経路の例。通過した経路の矢印を太く描いて
ある。また2度通った経路には矢印を2本描き、同じ状態より2度出力された記号に
は2本の下線を引いた。
\end{quotation}
\end{figure}

では次に隠れマルコフモデルにおいて、配列群\(x\)が観測されたときの、
\(P(x|\theta)\)における\(\theta\)の最尤推定量を求めることを考えましょう。
まず式\ref{EM_QQ}で\(y\)を観測不能な変数である\(\pi\)に置き換えて、

\begin{equation}
Q(\theta|\theta^{t})=\sum_{\pi}P(\pi|x,\theta^{t})\log P(x, \pi|\theta)
\label{hmm_em1}
\end{equation}

\noindent
とします。パラメータ\(\theta\)を持つ図\ref{hmm_count}のような隠れマ
ルコフモデルにおいて、経路\(\pi=({\rm start}, \pi_{1},\cdots, \pi_{L}, 
{\rm end})\)を通り、配列\(x\)が出力される確率は、

\begin{equation}
P(x,\pi|\theta)=t({\rm start} \to \pi_{1})\prod_{i=1}^{L}e_{\pi_{i}}(x_{i})t(\pi_{i} \to \pi_{i+1})
\label{hmm_bsc1}
\end{equation}

\noindent
となります。但し\(L\)は配列の長さ＝通過した記号を出力する状態の数で、
\(\pi_{L+1}={\rm end}\)とします。

これは通った状態の順序に着目した定式化の方法ですが、これを順序には特に
こだわらず、各状態および状態遷移を使用した回数に着目した定式化を行ってみましょう。
図\ref{hmm_count}には、塩基配列"TACGATG"が出力されたときに通った経路を示して
あります。式\ref{hmm_bsc1}を用いて、図\ref{hmm_count}のような経路を通ってこのような
塩基配列が出力される確率を表すと、

\begin{displaymath}
e_{1}({\rm T})
t(1 \to 3)
e_{3}({\rm A})
t(3 \to 4)
e_{4}({\rm C})
t(4 \to 2)
e_{2}({\rm G})
t(2 \to 3)
e_{3}({\rm A})
t(3 \to 4)
\end{displaymath}
\begin{displaymath}
\ \ \ \ \ \ \ \ \times
e_{4}({\rm T})
t(4 \to 5)
e_{5}({\rm G})
\end{displaymath}

\noindent
ですが、これを状態やその遷移ごとにまとめると、

\begin{displaymath}
e_{1}({\rm T})^{1}
e_{2}({\rm G})^{1}
e_{3}({\rm A})^{2}
e_{4}({\rm C})^{1}
t(1 \to 3)^{1}
t(2 \to 3)^{1}
t(3 \to 4)^{2}
t(4 \to 2)^{1}
\end{displaymath}

\noindent
となります。但し\(e\)のべき乗項はその状態においてその塩基が出力された回数、
\(t\)のべき乗項はその状態遷移が使われた回数です。
これを一般化して、今経路\(\pi\)上において、状態\(k\)か
ら状態\(l\)への遷移が使われる回数を\(N_{t(k \to l)}(\pi)\)、塩基\(b\)が
状態\(k\)において観測される回数を\(N_{e_{k}(b,\pi)}\)とします。すると、
式\ref{hmm_bsc1}は以下のように書き直せます。

\begin{equation}
P(x,\pi|\theta)=\prod_{k=1}^{K}\prod_{b}[e_{k}(b)_{|\theta}]^{N_{e_{k}}(b,\pi)}
\prod_{k=0}^{K}\prod_{l=1}^{K+1}[t(k \to l)_{|\theta}]^{N_{t(k \to l)}(\pi)}
\label{EM_multiply}
\end{equation}

\noindent
但し、\(K\)は\({\rm start}\)、\({\rm end}\)を除いた状態の数です。
また塩基を出力する各状態には状態番号1〜\(K\)が付けられ、\({\rm start}\)は
状態番号0とします。式\ref{EM_multiply}を式\ref{hmm_em1}に代入すれば、

\begin{displaymath}
Q(\theta|\theta^{t})=\sum_{\pi}P(\pi|x,\theta^{t}) \times
\end{displaymath}

\begin{equation}
\left[\sum_{k=1}^{K}\sum_{b}N_{e_{k}(b,\pi)}\log e_{k}(b)_{|\theta}+
\sum_{k=0}^{K}\sum_{l=1}^{K+1}N_{t(k \to l)}(\pi)\log t(k \to l)_{|\theta}\right]
\label{hmm_em_bsc2}
\end{equation}

\noindent
となります。

ここで期待値の定義を思い出して下さい。確率変数Xが\(p_{1},p_{2},\cdots, 
p_{n}\)(但し\(\sum_{i=1}^{n}p_{i}=1\))の確率で、値\(x_{1},x_{2},\cdots 
x_{n}\)を取るとき(\(P(X=x_{i})=p_{i}\))、\(E(X)=\sum_{i=1}^{n}p_{i}x_{i}\)
を確率変数\(X\)の期待値と呼んでいました。
\(N_{t(k \to l)}(\pi)\)を確率変数、\(P(\pi|x,\theta^{t})\)をその確率とすれば
期待値を表す式\ref{hmm_trans_exp}は、

\begin{equation}
N_{t(k \to l)|\theta^{t}}=\sum_{\pi}P(\pi|x,\theta^{t})N_{t(k \to l)}(\pi)
\label{hmm_EM_expN1}
\end{equation}

\noindent
と書き直すことができます。同様に、\(N_{e_{k}}(b,\pi)\)を確率変数、
\(P(\pi|x,\theta^{t})\)をその確率とすれば、式\ref{hmm_em_exp2}は

\begin{equation}
N_{e_{k}(b)|\theta^{t}}=\sum_{\pi}P(\pi|x,\theta^{t})N_{e_{k}}(b,\pi)
\label{hmm_EM_expN2}
\end{equation}

\noindent
と書き直すことができます。式\ref{hmm_EM_expN1},\ref{hmm_EM_expN2}を式
\ref{hmm_em_bsc2}に代入すると、

\begin{equation}
Q(\theta|\theta^{t})=\sum_{k=1}^{K}\sum_{b}N_{e_{k}(b)|\theta^{t}}\log e_{k}(b)_{|\theta}+
\sum_{k=0}^{K}\sum_{l=1}^{K+1}N_{t(k \to l)|\theta^{t}}\log t(k \to l)_{|\theta}
\label{hmm_em_maxi}
\end{equation}

\noindent
となります。さて、式\ref{hmm_em_maxi}を最大化するような\(e_{k}(b)_{|\theta}\)お
よび\(t(k \to l)_{|\theta}\)を求めましょう。まず、右辺第1項の最大化から考えると、
\(e^{0}_{k}(b)=\frac{N_{e_{k}(b)|\theta^{t}}}{\sum_{b'}N_{e_{k}(b')|\theta^{t}}}\)とおいて、式\ref{hmm_em_maxi}の第1項の\(e_{k}(b)\)が
\(e^{0}_{k}(b)\)の場合からそれ以外の場合(\(e_{k}(b)=e^{1}_{k}(b)\)とおく)
を引くと、

\begin{displaymath}
\sum_{k=1}^{K}\sum_{b}N_{e_{k}(b)|\theta^{t}}\log e^{0}_{k}(b)
-\sum_{k=1}^{K}\sum_{b}N_{e_{k}(b)|\theta^{t}}\log e^{1}_{k}(b)
\end{displaymath}

\begin{equation}
=\sum_{k=1}^{K}\sum_{b}N_{e_{k}(b)|\theta^{t}}\log \frac{e^{0}_{k}(b)}{e^{1}_{k}(b)}
=\sum_{k=1}^{K}\left(\sum_{b'}N_{e_{k}(b')|\theta^{t}}\right)
\sum_{b}e^{0}_{k}(b)\log \frac{e^{0}_{k}(b)}{e^{1}_{k}(b)}
\label{hmm_eq11}
\end{equation}

\noindent
となります。
\(\sum_{b}e^{0}_{k}(b)\log \frac{e^{0}_{k}(b)}{e^{1}_{k}(b)}\)は増加情報
量であり0以上なので(節\ref{rel_entropy}参照)、式\ref{hmm_eq11}は\(e_{k}(b)=e^{0}_{k}(b)\)のと
きに最大となります。

次に式\ref{hmm_em_maxi}の第2項の最大化を考えましょう。まず、\(t^{0}(k \to l)=\frac{N_{t(k \to l)|\theta^{t}}}{\sum_{l'}N_{t(k 
\to l')|\theta^{t}}}\)とおき、式\ref{hmm_em_maxi}の第2項の\(t(k \to l)\)
が\(t^{0}(k \to l)\)の場合からそれ以外の場合(\(t(k \to l)=t^{1}(k \to 
l)\)とおく)を引くと、

\begin{displaymath}
\sum_{k=0}^{K}\sum_{l=1}^{K+1}N_{t(k \to l)|\theta^{t}}\log t^{0}(k \to l)
-\sum_{k=0}^{K}\sum_{l=1}^{K+1}N_{t(k \to l)|\theta^{t}}\log t^{1}(k \to l)
\end{displaymath}

\begin{displaymath}
=\sum_{k=0}^{K}\sum_{l=1}^{K+1}N_{t(k \to l)|\theta^{t}}\log \frac{t^{0}(k \to l)}{t^{1}(k \to l)}
\end{displaymath}
\begin{equation}
=\sum_{k=0}^{K}\sum_{l=1}^{K+1}\left(\sum_{l'}N_{t(k \to l')|\theta} \right)
t^{0}(k \to l) \log \frac{t^{0}(k \to l)}{t^{1}(k \to l)}
\label{hmm_eq10}
\end{equation}

\noindent
となります。\(\sum_{l}t^{0}(k \to l) \log \frac{t^{0}(k \to l)}{t^{1}(k 
\to l)}\)は増加情報量であり0以上となるので、式\ref{hmm_eq10}は\(t^{0}(k 
\to l)=t^{1}(k \to l)\)のときに最大値となります。以上の結果より式
\ref{hmm_em_maxi}は\(e_{k}(b)=e^{0}_{k}(b)\)、
\(t(k \to l)=t^{0}(k \to l)\)のときに最大となることが導かれました。

従って、隠れマルコフモデルのパラメータ\(\theta\)を推定するためのEMアルゴ
リズムは以下のようになります。

\begin{description}
\item[E-Step] 式\ref{hmm_em_maxi}の計算。現在の推定量
\(\theta^{t}\)を用い、\(t(k \to l)_{|\theta^{t}}\)(式\ref{hmm_trans_exp}を使う)および
\(N_{e_{k}(b)_|\theta^{t}}\)(式\ref{hmm_em_exp2}を使う)を計算する。
\item[M-Stem] 式\ref{hmm_em_maxi}の最大化。

\[
t(k \to l)_{|\theta^{t+1}}=\frac{N_{t(k \to l)|\theta^{t}}}{\sum_{l'}N_{t(k \to l')|\theta^{t}}}
,\ \ 
e_{k}(b)_{|\theta^{t+1}}=\frac{N_{e_{k}|\theta^{t}}}{\sum_{b'}N_{e_{k}(b')|\theta^{t}}}
\]
で次の推定量\(\theta^{t+1}\)を求める。
\end{description}


